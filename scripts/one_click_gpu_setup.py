#!/usr/bin/env python3
"""
ä¸€é”®GPUé…ç½®è„šæœ¬ - å‚»ç“œå¼GPUé…ç½®
è‡ªåŠ¨æ£€æµ‹ç¡¬ä»¶ç¯å¢ƒå¹¶å®‰è£…æœ€é€‚åˆçš„GPUåŠ é€Ÿç»„ä»¶
"""

import sys
import subprocess
import platform
import logging
from pathlib import Path

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(message)s')
logger = logging.getLogger(__name__)


def print_banner():
    """æ‰“å°æ¨ªå¹…"""
    print("=" * 60)
    print("ğŸš€ AIæ¢è„¸å·¥å…· - ä¸€é”®GPUé…ç½®")
    print("=" * 60)
    print("è‡ªåŠ¨æ£€æµ‹æ‚¨çš„ç¡¬ä»¶ç¯å¢ƒå¹¶é…ç½®æœ€ä½³çš„GPUåŠ é€Ÿæ–¹æ¡ˆ")
    print()


def detect_gpu_environment():
    """æ£€æµ‹GPUç¯å¢ƒ"""
    try:
        # æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
        project_root = Path(__file__).parent.parent
        sys.path.insert(0, str(project_root))
        
        from utils.gpu_detector import GPUDetector
        
        print("ğŸ” æ­£åœ¨æ£€æµ‹GPUç¯å¢ƒ...")
        detector = GPUDetector()
        result = detector.detect_all()
        
        # æ‰“å°ç®€åŒ–çš„æ£€æµ‹æŠ¥å‘Š
        print(f"\nğŸ’» ç³»ç»Ÿ: {result['system']}")
        
        nvidia = result['nvidia_gpu']
        if nvidia.get('available'):
            print(f"ğŸ® NVIDIA GPU: âœ… æ£€æµ‹åˆ° {nvidia['count']} ä¸ªGPU")
            for gpu in nvidia['gpus']:
                print(f"   ğŸ“Š {gpu['name']} ({gpu['memory_mb']}MB)")
        else:
            print(f"ğŸ® NVIDIA GPU: âŒ æœªæ£€æµ‹åˆ°")
        
        cuda = result['cuda']
        if cuda.get('available'):
            print(f"ğŸš€ CUDA: âœ… å·²å®‰è£… ({cuda['version_info']})")
        else:
            print(f"ğŸš€ CUDA: âŒ æœªå®‰è£…")
        
        onnx = result['onnx_providers']
        if onnx.get('available'):
            providers = onnx['providers']
            print(f"ğŸ§  ONNX Runtime: âœ… å·²å®‰è£… (ç‰ˆæœ¬ {onnx['onnxruntime_version']})")
            if 'CUDAExecutionProvider' in providers:
                print(f"   ğŸš€ CUDAæ”¯æŒ: âœ…")
            elif 'DmlExecutionProvider' in providers:
                print(f"   âš¡ DirectMLæ”¯æŒ: âœ…")
            else:
                print(f"   ğŸ’» ä»…CPUæ”¯æŒ")
        else:
            print(f"ğŸ§  ONNX Runtime: âŒ æœªå®‰è£…")
        
        return result
        
    except ImportError as e:
        print(f"âŒ GPUæ£€æµ‹æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
        return None
    except Exception as e:
        print(f"âŒ GPUç¯å¢ƒæ£€æµ‹å¤±è´¥: {e}")
        return None


def get_recommended_action(gpu_result):
    """è·å–æ¨èçš„é…ç½®æ–¹æ¡ˆ"""
    if not gpu_result:
        return "install_cpu", "å®‰è£…CPUç‰ˆæœ¬ONNX Runtime"

    recommended = gpu_result.get('recommended_config', {})
    config_type = recommended.get('type', 'cpu_only')

    # æ£€æŸ¥NVIDIA GPUå’ŒCUDAå¯ç”¨æ€§
    nvidia = gpu_result.get('nvidia_gpu', {}).get('available', False)
    cuda = gpu_result.get('cuda', {}).get('available', False)
    system = gpu_result.get('system', '')

    # ä¼˜å…ˆæ¨èNVIDIA CUDAï¼ˆå³ä½¿å½“å‰ä½¿ç”¨DirectMLï¼‰
    if nvidia and cuda:
        # æ£€æŸ¥å½“å‰æ˜¯å¦å·²ç»æ˜¯CUDAé…ç½®
        onnx = gpu_result.get('onnx_providers', {})
        if (onnx.get('available') and 'CUDAExecutionProvider' in onnx.get('providers', [])):
            return "already_configured", "NVIDIA CUDA GPUåŠ é€Ÿå·²æ­£ç¡®é…ç½®"
        else:
            return "install_cuda", "å‡çº§åˆ°NVIDIA CUDA GPUæ”¯æŒ (æ€§èƒ½æ›´ä½³)"

    elif config_type == 'directml_gpu':
        return "already_configured", "DirectML GPUåŠ é€Ÿå·²é…ç½® (å¦‚éœ€æ›´å¥½æ€§èƒ½ï¼Œå»ºè®®å®‰è£…NVIDIAé©±åŠ¨å’ŒCUDA)"
    elif config_type == 'cuda_gpu':
        return "already_configured", "NVIDIA CUDA GPUåŠ é€Ÿå·²æ­£ç¡®é…ç½®"
    else:
        # éœ€è¦é…ç½®GPUæ”¯æŒ
        if system == "Windows":
            return "install_directml", "å®‰è£…DirectML GPUæ”¯æŒ (é€šç”¨)"
        else:
            return "install_cpu", "å®‰è£…CPUç‰ˆæœ¬ (å…¼å®¹æ€§æœ€ä½³)"


def install_onnxruntime_package(package_name, description):
    """å®‰è£…ONNX RuntimeåŒ…"""
    print(f"\nğŸ“¦ {description}...")
    
    try:
        # å…ˆå¸è½½ç°æœ‰ç‰ˆæœ¬
        print("ğŸ—‘ï¸ å¸è½½ç°æœ‰ONNX Runtimeç‰ˆæœ¬...")
        subprocess.run([
            sys.executable, '-m', 'pip', 'uninstall', 
            'onnxruntime', 'onnxruntime-gpu', 'onnxruntime-directml', '-y'
        ], check=False, capture_output=True)
        
        # å®‰è£…æ–°ç‰ˆæœ¬
        print(f"â¬‡ï¸ å®‰è£… {package_name}...")
        result = subprocess.run([
            sys.executable, '-m', 'pip', 'install', package_name
        ], capture_output=True, text=True)
        
        if result.returncode == 0:
            print(f"âœ… {package_name} å®‰è£…æˆåŠŸ!")
            return True
        else:
            print(f"âŒ å®‰è£…å¤±è´¥: {result.stderr}")
            return False
            
    except Exception as e:
        print(f"âŒ å®‰è£…è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        return False


def verify_installation():
    """éªŒè¯å®‰è£…ç»“æœ"""
    print("\nğŸ” éªŒè¯å®‰è£…ç»“æœ...")
    
    try:
        import onnxruntime as ort
        providers = ort.get_available_providers()
        
        print(f"ğŸ“‹ å¯ç”¨æä¾›è€…: {', '.join(providers)}")
        
        if 'CUDAExecutionProvider' in providers:
            print("ğŸš€ NVIDIA CUDA GPUåŠ é€Ÿ: âœ… å¯ç”¨")
            return "cuda"
        elif 'DmlExecutionProvider' in providers:
            print("âš¡ DirectML GPUåŠ é€Ÿ: âœ… å¯ç”¨")
            return "directml"
        elif 'CPUExecutionProvider' in providers:
            print("ğŸ’» CPUæ¨¡å¼: âœ… å¯ç”¨")
            return "cpu"
        else:
            print("âŒ æœªæ£€æµ‹åˆ°ä»»ä½•å¯ç”¨çš„æ‰§è¡Œæä¾›è€…")
            return "none"
            
    except ImportError:
        print("âŒ ONNX Runtimeå¯¼å…¥å¤±è´¥")
        return "none"
    except Exception as e:
        print(f"âŒ éªŒè¯å¤±è´¥: {e}")
        return "none"


def main():
    """ä¸»å‡½æ•°"""
    print_banner()
    
    # æ£€æµ‹GPUç¯å¢ƒ
    gpu_result = detect_gpu_environment()
    
    # è·å–æ¨èæ–¹æ¡ˆ
    action, description = get_recommended_action(gpu_result)
    
    print(f"\nğŸ¯ æ¨èæ–¹æ¡ˆ: {description}")
    
    if action == "already_configured":
        print("âœ… æ‚¨çš„GPUåŠ é€Ÿå·²æ­£ç¡®é…ç½®ï¼Œæ— éœ€é¢å¤–æ“ä½œ!")
        return True
    
    # ç¡®è®¤æ˜¯å¦ç»§ç»­
    print(f"\næ˜¯å¦è¦æ‰§è¡Œæ¨èçš„é…ç½®æ–¹æ¡ˆï¼Ÿ")
    print(f"æ–¹æ¡ˆ: {description}")
    
    try:
        choice = input("\nè¯·è¾“å…¥ y/Y ç»§ç»­ï¼Œå…¶ä»–é”®å–æ¶ˆ: ").strip().lower()
        if choice not in ['y', 'yes']:
            print("âŒ ç”¨æˆ·å–æ¶ˆæ“ä½œ")
            return False
    except KeyboardInterrupt:
        print("\nâŒ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        return False
    
    # æ‰§è¡Œå®‰è£…
    success = False
    
    if action == "install_cuda":
        success = install_onnxruntime_package("onnxruntime-gpu", "å®‰è£…NVIDIA CUDA GPUæ”¯æŒ")
    elif action == "install_directml":
        success = install_onnxruntime_package("onnxruntime-directml", "å®‰è£…DirectML GPUæ”¯æŒ")
    elif action == "install_cpu":
        success = install_onnxruntime_package("onnxruntime", "å®‰è£…CPUç‰ˆæœ¬ONNX Runtime")
    
    if success:
        # éªŒè¯å®‰è£…
        result_type = verify_installation()
        
        if result_type != "none":
            print("\nğŸ‰ GPUé…ç½®å®Œæˆ!")
            print("=" * 60)
            print("âœ… é…ç½®æˆåŠŸ! æ‚¨ç°åœ¨å¯ä»¥ä½¿ç”¨GPUåŠ é€ŸåŠŸèƒ½äº†")
            print("ğŸ’¡ è¯·é‡å¯AIæ¢è„¸ç¨‹åºä»¥ä½¿é…ç½®ç”Ÿæ•ˆ")
            print("=" * 60)
            return True
        else:
            print("\nâŒ é…ç½®éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥å®‰è£…è¿‡ç¨‹ä¸­çš„é”™è¯¯ä¿¡æ¯")
            return False
    else:
        print("\nâŒ é…ç½®å¤±è´¥ï¼Œè¯·æŸ¥çœ‹ä¸Šè¿°é”™è¯¯ä¿¡æ¯")
        return False


def silent_install(config_type="auto"):
    """é™é»˜å®‰è£…æ¨¡å¼ (ä¾›GUIè°ƒç”¨)"""
    try:
        # æ£€æµ‹ç¯å¢ƒ
        gpu_result = detect_gpu_environment()
        
        if config_type == "auto":
            action, _ = get_recommended_action(gpu_result)
        else:
            action = f"install_{config_type}"
        
        # æ‰§è¡Œå®‰è£…
        if action == "install_cuda":
            return install_onnxruntime_package("onnxruntime-gpu", "å®‰è£…NVIDIA CUDA GPUæ”¯æŒ")
        elif action == "install_directml":
            return install_onnxruntime_package("onnxruntime-directml", "å®‰è£…DirectML GPUæ”¯æŒ")
        elif action == "install_cpu":
            return install_onnxruntime_package("onnxruntime", "å®‰è£…CPUç‰ˆæœ¬ONNX Runtime")
        else:
            return True  # å·²é…ç½®
            
    except Exception as e:
        print(f"âŒ é™é»˜å®‰è£…å¤±è´¥: {e}")
        return False


if __name__ == "__main__":
    try:
        success = main()
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print("\nâŒ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ ç¨‹åºå¼‚å¸¸: {e}")
        sys.exit(1)
