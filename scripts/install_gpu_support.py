#!/usr/bin/env python3
"""
GPUåŠ é€Ÿæ”¯æŒå®‰è£…è„šæœ¬
è‡ªåŠ¨æ£€æµ‹GPUç±»å‹å¹¶å®‰è£…å¯¹åº”çš„ONNX Runtimeç‰ˆæœ¬
"""

import subprocess
import sys
import platform
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
logger = logging.getLogger(__name__)

def run_command(cmd, check=True):
    """è¿è¡Œå‘½ä»¤å¹¶è¿”å›ç»“æœ"""
    try:
        result = subprocess.run(cmd, shell=True, capture_output=True, text=True, check=check)
        return result.returncode == 0, result.stdout, result.stderr
    except subprocess.CalledProcessError as e:
        return False, e.stdout, e.stderr

def check_nvidia_gpu():
    """æ£€æŸ¥NVIDIA GPU"""
    logger.info("æ£€æŸ¥NVIDIA GPU...")
    
    # æ£€æŸ¥nvidia-smiå‘½ä»¤
    success, stdout, stderr = run_command("nvidia-smi", check=False)
    if success:
        logger.info("âœ… æ£€æµ‹åˆ°NVIDIA GPU")
        return True
    else:
        logger.info("âŒ æœªæ£€æµ‹åˆ°NVIDIA GPUæˆ–é©±åŠ¨")
        return False

def check_cuda():
    """æ£€æŸ¥CUDAå®‰è£…"""
    logger.info("æ£€æŸ¥CUDAå®‰è£…...")
    
    success, stdout, stderr = run_command("nvcc --version", check=False)
    if success:
        logger.info("âœ… æ£€æµ‹åˆ°CUDA")
        return True
    else:
        logger.info("âŒ æœªæ£€æµ‹åˆ°CUDA")
        return False

def check_current_onnxruntime():
    """æ£€æŸ¥å½“å‰ONNX Runtimeç‰ˆæœ¬"""
    logger.info("æ£€æŸ¥å½“å‰ONNX Runtime...")
    
    try:
        import onnxruntime as ort
        providers = ort.get_available_providers()
        logger.info(f"å½“å‰ONNX Runtimeæä¾›è€…: {providers}")
        
        if 'CUDAExecutionProvider' in providers:
            logger.info("âœ… å·²å®‰è£…GPUç‰ˆæœ¬çš„ONNX Runtime")
            return 'gpu'
        elif 'DmlExecutionProvider' in providers:
            logger.info("âœ… å·²å®‰è£…DirectMLç‰ˆæœ¬çš„ONNX Runtime")
            return 'directml'
        else:
            logger.info("âš ï¸ å½“å‰ä¸ºCPUç‰ˆæœ¬çš„ONNX Runtime")
            return 'cpu'
    except ImportError:
        logger.info("âŒ æœªå®‰è£…ONNX Runtime")
        return 'none'

def install_onnxruntime_gpu():
    """å®‰è£…GPUç‰ˆæœ¬çš„ONNX Runtime"""
    logger.info("å®‰è£…GPUç‰ˆæœ¬çš„ONNX Runtime...")
    
    # å¸è½½ç°æœ‰ç‰ˆæœ¬
    logger.info("å¸è½½ç°æœ‰ONNX Runtime...")
    run_command("pip uninstall onnxruntime onnxruntime-gpu onnxruntime-directml -y", check=False)
    
    # å®‰è£…GPUç‰ˆæœ¬
    logger.info("å®‰è£…onnxruntime-gpu...")
    success, stdout, stderr = run_command("pip install onnxruntime-gpu")
    
    if success:
        logger.info("âœ… GPUç‰ˆæœ¬å®‰è£…æˆåŠŸ")
        return True
    else:
        logger.error(f"âŒ GPUç‰ˆæœ¬å®‰è£…å¤±è´¥: {stderr}")
        return False

def install_onnxruntime_directml():
    """å®‰è£…DirectMLç‰ˆæœ¬çš„ONNX Runtime"""
    logger.info("å®‰è£…DirectMLç‰ˆæœ¬çš„ONNX Runtime...")
    
    # å¸è½½ç°æœ‰ç‰ˆæœ¬
    logger.info("å¸è½½ç°æœ‰ONNX Runtime...")
    run_command("pip uninstall onnxruntime onnxruntime-gpu onnxruntime-directml -y", check=False)
    
    # å®‰è£…DirectMLç‰ˆæœ¬
    logger.info("å®‰è£…onnxruntime-directml...")
    success, stdout, stderr = run_command("pip install onnxruntime-directml")
    
    if success:
        logger.info("âœ… DirectMLç‰ˆæœ¬å®‰è£…æˆåŠŸ")
        return True
    else:
        logger.error(f"âŒ DirectMLç‰ˆæœ¬å®‰è£…å¤±è´¥: {stderr}")
        return False

def install_onnxruntime_cpu():
    """å®‰è£…CPUç‰ˆæœ¬çš„ONNX Runtime"""
    logger.info("å®‰è£…CPUç‰ˆæœ¬çš„ONNX Runtime...")
    
    # å¸è½½ç°æœ‰ç‰ˆæœ¬
    run_command("pip uninstall onnxruntime onnxruntime-gpu onnxruntime-directml -y", check=False)
    
    # å®‰è£…CPUç‰ˆæœ¬
    success, stdout, stderr = run_command("pip install onnxruntime")
    
    if success:
        logger.info("âœ… CPUç‰ˆæœ¬å®‰è£…æˆåŠŸ")
        return True
    else:
        logger.error(f"âŒ CPUç‰ˆæœ¬å®‰è£…å¤±è´¥: {stderr}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ GPUåŠ é€Ÿæ”¯æŒå®‰è£…è„šæœ¬")
    print("=" * 50)

    # ä½¿ç”¨æ–°çš„GPUæ£€æµ‹å™¨
    try:
        sys.path.append(str(Path(__file__).parent.parent))
        from utils.gpu_detector import GPUDetector

        detector = GPUDetector()
        gpu_result = detector.detect_all()

        # æ‰“å°è¯¦ç»†æ£€æµ‹æŠ¥å‘Š
        detector.print_detailed_report(gpu_result)

        # æ ¹æ®æ£€æµ‹ç»“æœæä¾›å®‰è£…å»ºè®®
        recommended_config = gpu_result.get('recommended_config', {})
        config_type = recommended_config.get('type', 'cpu_only')

        print("\n" + "=" * 50)
        print("ğŸ¯ å®‰è£…å»ºè®®")
        print("=" * 50)

        if config_type == 'cuda_gpu':
            print("âœ… æ£€æµ‹åˆ°å®Œæ•´çš„NVIDIA GPU + CUDAç¯å¢ƒ")
            print("æ¨è: å·²ç»é…ç½®å®Œæˆï¼Œæ— éœ€é¢å¤–å®‰è£…")

        elif config_type == 'directml_gpu':
            print("âœ… æ£€æµ‹åˆ°DirectML GPUæ”¯æŒ")
            print("æ¨è: å·²ç»é…ç½®å®Œæˆï¼Œæ— éœ€é¢å¤–å®‰è£…")

        else:
            print("âŒ GPUåŠ é€Ÿä¸å¯ç”¨")
            print(f"åŸå› : {recommended_config.get('reason', 'æœªçŸ¥')}")
            print("\nğŸ”§ è§£å†³æ–¹æ¡ˆ:")

            # æ£€æŸ¥å…·ä½“é—®é¢˜å¹¶æä¾›è§£å†³æ–¹æ¡ˆ
            nvidia = gpu_result.get('nvidia_gpu', {})
            cuda = gpu_result.get('cuda', {})
            onnx = gpu_result.get('onnx_providers', {})

            if not nvidia.get('available'):
                print("1. å®‰è£…NVIDIA GPUé©±åŠ¨:")
                print("   - è®¿é—® https://www.nvidia.com/drivers/")
                print("   - ä¸‹è½½å¹¶å®‰è£…æœ€æ–°é©±åŠ¨")

            if not cuda.get('available'):
                print("2. å®‰è£…CUDA Toolkit:")
                print("   - è®¿é—® https://developer.nvidia.com/cuda-downloads")
                print("   - ä¸‹è½½å¹¶å®‰è£…CUDA 11.8æˆ–æ›´é«˜ç‰ˆæœ¬")

            if not onnx.get('available') or 'CUDAExecutionProvider' not in onnx.get('providers', []):
                print("3. å®‰è£…GPUç‰ˆæœ¬çš„ONNX Runtime:")
                current_version = check_current_onnxruntime()
                if current_version != 'gpu':
                    choice = input("   æ˜¯å¦ç°åœ¨å®‰è£…GPUç‰ˆæœ¬çš„ONNX Runtime? (y/n): ").lower()
                    if choice == 'y':
                        if install_onnxruntime_gpu():
                            print("   âœ… GPUç‰ˆæœ¬å®‰è£…å®Œæˆ!")
                        else:
                            print("   âŒ GPUç‰ˆæœ¬å®‰è£…å¤±è´¥")
                            # å°è¯•DirectMLä½œä¸ºå¤‡é€‰
                            if platform.system() == "Windows":
                                print("   ğŸ”„ å°è¯•å®‰è£…DirectMLç‰ˆæœ¬...")
                                if install_onnxruntime_directml():
                                    print("   âœ… DirectMLç‰ˆæœ¬å®‰è£…å®Œæˆ!")
                                else:
                                    print("   âŒ DirectMLç‰ˆæœ¬ä¹Ÿå®‰è£…å¤±è´¥")
                    else:
                        print("   è·³è¿‡GPUç‰ˆæœ¬å®‰è£…")
                else:
                    print("   âœ… å·²å®‰è£…GPUç‰ˆæœ¬")

    except ImportError:
        print("âŒ GPUæ£€æµ‹å™¨ä¸å¯ç”¨ï¼Œä½¿ç”¨ä¼ ç»Ÿæ£€æµ‹æ–¹æ³•")
        # å›é€€åˆ°åŸæœ‰é€»è¾‘
        _legacy_main()

    print("\n" + "=" * 50)
    print("å®‰è£…å®Œæˆ! è¯·é‡æ–°å¯åŠ¨AIæ¢è„¸åº”ç”¨ç¨‹åº")

def _legacy_main():
    """ä¼ ç»Ÿæ£€æµ‹æ–¹æ³•"""
    # æ£€æŸ¥æ“ä½œç³»ç»Ÿ
    os_name = platform.system()
    logger.info(f"æ“ä½œç³»ç»Ÿ: {os_name}")

    # æ£€æŸ¥å½“å‰ONNX RuntimeçŠ¶æ€
    current_version = check_current_onnxruntime()

    # æ£€æŸ¥GPUæ”¯æŒ
    has_nvidia = check_nvidia_gpu()
    has_cuda = check_cuda()

    # å†³å®šå®‰è£…ç­–ç•¥
    if has_nvidia and has_cuda:
        logger.info("ğŸ¯ æ¨èå®‰è£…: CUDA GPUç‰ˆæœ¬")
        if current_version != 'gpu':
            choice = input("æ˜¯å¦å®‰è£…GPUç‰ˆæœ¬çš„ONNX Runtime? (y/n): ").lower()
            if choice == 'y':
                if install_onnxruntime_gpu():
                    print("\nâœ… GPUåŠ é€Ÿå®‰è£…å®Œæˆ!")
                else:
                    print("\nâŒ GPUåŠ é€Ÿå®‰è£…å¤±è´¥")
            else:
                print("è·³è¿‡GPUç‰ˆæœ¬å®‰è£…")
        else:
            print("âœ… å·²å®‰è£…GPUç‰ˆæœ¬ï¼Œæ— éœ€é‡å¤å®‰è£…")

    elif os_name == "Windows":
        logger.info("ğŸ¯ æ¨èå®‰è£…: DirectMLç‰ˆæœ¬ (æ”¯æŒAMD/Intel GPU)")
        if current_version != 'directml':
            choice = input("æ˜¯å¦å®‰è£…DirectMLç‰ˆæœ¬çš„ONNX Runtime? (y/n): ").lower()
            if choice == 'y':
                if install_onnxruntime_directml():
                    print("\nâœ… DirectMLåŠ é€Ÿå®‰è£…å®Œæˆ!")
                else:
                    print("\nâŒ DirectMLåŠ é€Ÿå®‰è£…å¤±è´¥")
            else:
                print("è·³è¿‡DirectMLç‰ˆæœ¬å®‰è£…")
        else:
            print("âœ… å·²å®‰è£…DirectMLç‰ˆæœ¬ï¼Œæ— éœ€é‡å¤å®‰è£…")

    else:
        logger.info("ğŸ¯ æ¨èå®‰è£…: CPUç‰ˆæœ¬")
        if current_version == 'none':
            if install_onnxruntime_cpu():
                print("\nâœ… CPUç‰ˆæœ¬å®‰è£…å®Œæˆ!")
            else:
                print("\nâŒ CPUç‰ˆæœ¬å®‰è£…å¤±è´¥")
        else:
            print("âœ… å·²å®‰è£…ONNX Runtime")

if __name__ == "__main__":
    main()
