#!/usr/bin/env python3
"""
GPUé…ç½®é‡ç½®å·¥å…·
æ¸…é™¤æ‰€æœ‰GPUç›¸å…³é…ç½®ï¼Œæ¢å¤åˆ°åˆå§‹çŠ¶æ€ï¼Œç”¨äºåœ¨æ–°ç”µè„‘ä¸Šé‡æ–°æ£€æµ‹GPU
"""

import sys
import json
import shutil
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

def reset_gpu_config():
    """é‡ç½®GPUé…ç½®åˆ°åˆå§‹çŠ¶æ€"""
    print("ğŸ”„ æ­£åœ¨é‡ç½®GPUé…ç½®...")
    
    # 1. åˆ é™¤GPUå†…å­˜é…ç½®æ–‡ä»¶
    config_dir = project_root / "config"
    gpu_config_file = config_dir / "gpu_memory.json"
    
    if gpu_config_file.exists():
        gpu_config_file.unlink()
        print("âœ… å·²åˆ é™¤GPUå†…å­˜é…ç½®æ–‡ä»¶")
    
    # 2. æ¸…ç†å¯èƒ½çš„ç¼“å­˜ç›®å½•
    cache_dirs = [
        project_root / "__pycache__",
        project_root / "core" / "__pycache__",
        project_root / "gui" / "__pycache__",
        project_root / "utils" / "__pycache__",
        project_root / "scripts" / "__pycache__"
    ]
    
    for cache_dir in cache_dirs:
        if cache_dir.exists():
            shutil.rmtree(cache_dir, ignore_errors=True)
            print(f"âœ… å·²æ¸…ç†ç¼“å­˜ç›®å½•: {cache_dir.name}")
    
    # 3. åˆ›å»ºé»˜è®¤é…ç½®ç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    config_dir.mkdir(exist_ok=True)
    
    print("\nğŸ¯ GPUé…ç½®å·²é‡ç½®å®Œæˆï¼")
    print("\nğŸ“‹ ä¸‹æ¬¡å¯åŠ¨æ—¶å°†ä¼š:")
    print("   1. é‡æ–°æ£€æµ‹GPUç¯å¢ƒ")
    print("   2. è‡ªåŠ¨é€‰æ‹©æœ€ä½³é…ç½®")
    print("   3. å¯ä»¥ä½¿ç”¨å‚»ç“œå¼GPUé…ç½®å‘å¯¼")
    
    return True

def test_gpu_detection():
    """æµ‹è¯•GPUæ£€æµ‹åŠŸèƒ½"""
    print("\nğŸ” æµ‹è¯•GPUæ£€æµ‹åŠŸèƒ½...")
    
    try:
        from utils.gpu_detector import GPUDetector
        
        detector = GPUDetector()
        result = detector.detect_all()
        
        print(f"\nğŸ’» ç³»ç»Ÿ: {result['system']}")
        
        # NVIDIA GPU
        nvidia = result['nvidia_gpu']
        if nvidia.get('available'):
            print(f"ğŸ® NVIDIA GPU: âœ… æ£€æµ‹åˆ° {nvidia['count']} ä¸ªGPU")
            for gpu in nvidia['gpus']:
                print(f"   ğŸ“Š {gpu['name']} ({gpu['memory_mb']}MB)")
        else:
            print("ğŸ® NVIDIA GPU: âŒ æœªæ£€æµ‹åˆ°")
        
        # CUDA
        cuda = result['cuda']
        if cuda.get('available'):
            print(f"ğŸš€ CUDA: âœ… å·²å®‰è£… ({cuda['version_info']})")
        else:
            print("ğŸš€ CUDA: âŒ æœªå®‰è£…")
        
        # ONNX Runtimeæä¾›è€…
        onnx = result['onnx_providers']
        if onnx.get('available'):
            providers = onnx['providers']
            print(f"ğŸ”§ ONNX Runtime: âœ… å¯ç”¨æä¾›è€…: {providers}")
        else:
            print("ğŸ”§ ONNX Runtime: âŒ ä¸å¯ç”¨")
        
        # æ¨èé…ç½®
        recommended = result['recommended_config']
        if recommended:
            print(f"\nğŸ¯ æ¨èé…ç½®:")
            print(f"   ğŸ“‹ ç±»å‹: {recommended['description']}")
            print(f"   ğŸš€ æä¾›è€…: {recommended['provider']}")
            print(f"   ğŸ“Š æ€§èƒ½ç­‰çº§: {recommended['performance']}")
            print(f"   âš¡ GPUåŠ é€Ÿ: {'å¯ç”¨' if recommended['gpu_enabled'] else 'ç¦ç”¨'}")
            print(f"   ğŸ’¡ åŸå› : {recommended['reason']}")
        
        return True
        
    except Exception as e:
        print(f"âŒ GPUæ£€æµ‹å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸ”§ GPUé…ç½®é‡ç½®å·¥å…·")
    print("=" * 60)
    
    # é‡ç½®é…ç½®
    if reset_gpu_config():
        # æµ‹è¯•æ£€æµ‹åŠŸèƒ½
        test_gpu_detection()
        
        print("\n" + "=" * 60)
        print("âœ… é‡ç½®å®Œæˆï¼ç°åœ¨å¯ä»¥åœ¨æ–°ç”µè„‘ä¸Šé‡æ–°é…ç½®GPUäº†")
        print("ğŸ’¡ å»ºè®®: è¿è¡Œ 'python scripts/one_click_gpu_setup.py' è¿›è¡Œè‡ªåŠ¨é…ç½®")
        print("=" * 60)
    else:
        print("âŒ é‡ç½®å¤±è´¥")
        return False
    
    return True

if __name__ == "__main__":
    main()
